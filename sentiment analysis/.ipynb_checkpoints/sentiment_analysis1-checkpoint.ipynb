{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean words, i.e. remove stopwords and punctuation\n",
    "def clean_words(words, stopwords_english):\n",
    "    words_clean = []\n",
    "#     print(type(words))\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords_english and word not in string.punctuation:\n",
    "            words_clean.append(word)    \n",
    "    return words_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extractor function for unigram\n",
    "def bag_of_words(words):    \n",
    "    words_dictionary = dict([word, True] for word in words)    \n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extractor function for ngrams (bigram)\n",
    "def bag_of_ngrams(words, n=2):\n",
    "    words_ng = []\n",
    "    for item in iter(ngrams(words, n)):\n",
    "        words_ng.append(item)\n",
    "    words_dictionary = dict([word, True] for word in words_ng)    \n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"It was a very good movie.\"\n",
    "words = word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'was', 'a', 'very', 'good', 'movie', '.']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('it', 'was'): True,\n",
       " ('was', 'a'): True,\n",
       " ('a', 'very'): True,\n",
       " ('very', 'good'): True,\n",
       " ('good', 'movie'): True,\n",
       " ('movie', '.'): True}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_ngrams(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'movie']\n"
     ]
    }
   ],
   "source": [
    "words_clean = clean_words(words, stopwords_english)\n",
    "print (words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words = ['above', 'below', 'off', 'over', 'under', 'more', 'most', 'such', 'no', 'nor', 'not', 'only', 'so', 'than', 'too', 'very', 'just', 'but']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'good', 'movie']\n"
     ]
    }
   ],
   "source": [
    "stopwords_english_for_bigrams = set(stopwords_english) - set(important_words)\n",
    " \n",
    "words_clean_for_bigrams = clean_words(words, stopwords_english_for_bigrams)\n",
    "print (words_clean_for_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': True, 'movie': True}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_features = bag_of_words(words_clean)\n",
    "unigram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('very', 'good'): True, ('good', 'movie'): True}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_features = bag_of_ngrams(words_clean_for_bigrams)\n",
    "bigram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': True, 'movie': True, ('very', 'good'): True, ('good', 'movie'): True}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both unigram and bigram features\n",
    "all_features = unigram_features.copy()\n",
    "all_features.update(bigram_features)\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a new function that extracts all features\n",
    "# i.e. that extracts both unigram and bigrams features\n",
    "def bag_of_all_words(words, n=2):\n",
    "    words_clean = clean_words(words, stopwords_english)\n",
    "    words_clean_for_bigrams = clean_words(words, stopwords_english_for_bigrams)\n",
    " \n",
    "    unigram_features = bag_of_words(words_clean)\n",
    "    bigram_features = bag_of_ngrams(words_clean_for_bigrams)\n",
    " \n",
    "    all_features = unigram_features.copy()\n",
    "    all_features.update(bigram_features)\n",
    " \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': True, 'movie': True, ('very', 'good'): True, ('good', 'movie'): True}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_all_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews \n",
    " \n",
    "pos_reviews = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    words = movie_reviews.words(fileid)\n",
    "    pos_reviews.append(words)\n",
    " \n",
    "neg_reviews = []\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    words = movie_reviews.words(fileid)\n",
    "    neg_reviews.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive reviews feature set\n",
    "pos_reviews_set = []\n",
    "for words in pos_reviews:\n",
    "    pos_reviews_set.append((bag_of_all_words(words), 'pos'))\n",
    " \n",
    "# negative reviews feature set\n",
    "neg_reviews_set = []\n",
    "for words in neg_reviews:\n",
    "    neg_reviews_set.append((bag_of_all_words(words), 'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pandas.read_csv('clean_tweet2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omg\n",
      "handed\n",
      "hmmmm\n",
      "thanks\n",
      "feeling\n",
      "you\n",
      "goodbye\n",
      "uploading\n",
      "so\n",
      "do\n",
      "health\n",
      "go\n",
      "bathroom\n",
      "boom\n",
      "go\n",
      "going\n",
      "always\n",
      "bend\n",
      "get\n",
      "hate\n",
      "really\n",
      "jin\n",
      "just\n",
      "just\n",
      "oh\n",
      "pleased\n",
      "rose\n",
      "thanks\n",
      "that\n",
      "there\n",
      "trae\n",
      "true\n",
      "wide\n",
      "yeah\n",
      "poemsunder\n",
      "that\n",
      "goooood\n",
      "know\n",
      "the\n",
      "the\n",
      "hummin\n",
      "sigh\n",
      "aiqht\n",
      "triiiiiii\n",
      "hot\n",
      "beach\n",
      "what\n",
      "canaveral\n",
      "progressing\n",
      "taylorrhicks\n",
      "thestreetforce\n",
      "makes\n",
      "my\n",
      "video\n",
      "am\n",
      "call\n",
      "just\n",
      "and\n",
      "see\n",
      "facebook\n",
      "you\n",
      "lol\n",
      "is\n",
      "tell\n",
      "told\n",
      "the\n",
      "yes\n",
      "are\n",
      "hope\n",
      "awesome\n",
      "am\n",
      "pick\n",
      "think\n",
      "watch\n",
      "thanks\n",
      "followers\n",
      "ll\n",
      "yall\n",
      "congrats\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-fb1984f1bdb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpos_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-340-fb1984f1bdb2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpos_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pos_reviews = tweet_data[tweet_data.sentiment == 1].text.str.lower().str.split()\n",
    "pos_reviews = [value for (index, value) in pos_reviews.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews = list(tweet_data[tweet_data.sentiment == 0].text.str.lower().str.split())\n",
    "# len(neg_reviews)+len(pos_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-337-5c76e2d412d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpos_reviews_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpos_reviews_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_of_all_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# # negative reviews feature set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-282-4f1b5ece5494>\u001b[0m in \u001b[0;36mbag_of_all_words\u001b[0;34m(words, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# i.e. that extracts both unigram and bigrams features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbag_of_all_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwords_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopwords_english\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwords_clean_for_bigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopwords_english_for_bigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-270-5a92ffdc86f2>\u001b[0m in \u001b[0;36mclean_words\u001b[0;34m(words, stopwords_english)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwords_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print(type(words))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords_english\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "# positive reviews feature set\n",
    "# import numpy as np\n",
    "# n_features = np.arange(1000,100001,10000)\n",
    "\n",
    "pos_reviews_set = []\n",
    "for (index, value) in pos_reviews.items():\n",
    "    pos_reviews_set.append((bag_of_all_words(value), 'pos'))\n",
    " \n",
    "# # negative reviews feature set\n",
    "# neg_reviews_set = []\n",
    "# for words in neg_reviews[:(len(pos_reviews_set)/2)]:\n",
    "#     neg_reviews_set.append((bag_of_all_words(words), 'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'omg': True, 'already': True, ('omg', 'already'): True}, 'pos'),\n",
       " ({'handed': True,\n",
       "   'uniform': True,\n",
       "   'today': True,\n",
       "   'miss': True,\n",
       "   'already': True,\n",
       "   ('handed', 'uniform'): True,\n",
       "   ('uniform', 'today'): True,\n",
       "   ('today', 'miss'): True,\n",
       "   ('miss', 'already'): True},\n",
       "  'pos'),\n",
       " ({'hmmmm': True,\n",
       "   'wonder': True,\n",
       "   'number': True,\n",
       "   ('hmmmm', 'wonder'): True,\n",
       "   ('wonder', 'number'): True},\n",
       "  'pos'),\n",
       " ({'thanks': True,\n",
       "   'haters': True,\n",
       "   'face': True,\n",
       "   'day': True,\n",
       "   ('thanks', 'haters'): True,\n",
       "   ('haters', 'face'): True,\n",
       "   ('face', 'day'): True},\n",
       "  'pos'),\n",
       " ({'feeling': True,\n",
       "   'strangely': True,\n",
       "   'fine': True,\n",
       "   'gonna': True,\n",
       "   'go': True,\n",
       "   'listen': True,\n",
       "   'semisonic': True,\n",
       "   'celebrate': True,\n",
       "   ('feeling', 'strangely'): True,\n",
       "   ('strangely', 'fine'): True,\n",
       "   ('fine', 'gonna'): True,\n",
       "   ('gonna', 'go'): True,\n",
       "   ('go', 'listen'): True,\n",
       "   ('listen', 'semisonic'): True,\n",
       "   ('semisonic', 'celebrate'): True},\n",
       "  'pos'),\n",
       " ({'one': True,\n",
       "   'see': True,\n",
       "   'cause': True,\n",
       "   'else': True,\n",
       "   'following': True,\n",
       "   'pretty': True,\n",
       "   'awesome': True,\n",
       "   ('only', 'one'): True,\n",
       "   ('one', 'see'): True,\n",
       "   ('see', 'cause'): True,\n",
       "   ('cause', 'no'): True,\n",
       "   ('no', 'one'): True,\n",
       "   ('one', 'else'): True,\n",
       "   ('else', 'following'): True,\n",
       "   ('following', 'pretty'): True,\n",
       "   ('pretty', 'awesome'): True},\n",
       "  'pos'),\n",
       " ({'goodbye': True,\n",
       "   'exams': True,\n",
       "   'hello': True,\n",
       "   'alcohol': True,\n",
       "   'tonight': True,\n",
       "   ('goodbye', 'exams'): True,\n",
       "   ('exams', 'hello'): True,\n",
       "   ('hello', 'alcohol'): True,\n",
       "   ('alcohol', 'tonight'): True},\n",
       "  'pos'),\n",
       " ({'uploading': True,\n",
       "   'pictures': True,\n",
       "   'friendster': True,\n",
       "   ('uploading', 'pictures'): True,\n",
       "   ('pictures', 'friendster'): True},\n",
       "  'pos'),\n",
       " ({'wrote': True,\n",
       "   'something': True,\n",
       "   'last': True,\n",
       "   'week': True,\n",
       "   'got': True,\n",
       "   'call': True,\n",
       "   'someone': True,\n",
       "   'new': True,\n",
       "   'york': True,\n",
       "   'office': True,\n",
       "   ('so', 'wrote'): True,\n",
       "   ('wrote', 'something'): True,\n",
       "   ('something', 'last'): True,\n",
       "   ('last', 'week'): True,\n",
       "   ('week', 'got'): True,\n",
       "   ('got', 'call'): True,\n",
       "   ('call', 'someone'): True,\n",
       "   ('someone', 'new'): True,\n",
       "   ('new', 'york'): True,\n",
       "   ('york', 'office'): True},\n",
       "  'pos'),\n",
       " ({'need': True,\n",
       "   'even': True,\n",
       "   'say': True,\n",
       "   'well': True,\n",
       "   'go': True,\n",
       "   'anyways': True,\n",
       "   'chris': True,\n",
       "   'cornell': True,\n",
       "   'chicago': True,\n",
       "   'tonight': True,\n",
       "   ('need', 'even'): True,\n",
       "   ('even', 'say'): True,\n",
       "   ('say', 'well'): True,\n",
       "   ('well', 'go'): True,\n",
       "   ('go', 'anyways'): True,\n",
       "   ('anyways', 'chris'): True,\n",
       "   ('chris', 'cornell'): True,\n",
       "   ('cornell', 'chicago'): True,\n",
       "   ('chicago', 'tonight'): True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
